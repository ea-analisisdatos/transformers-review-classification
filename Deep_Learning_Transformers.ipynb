{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymywFF4vD3y4"
      },
      "source": [
        "# üè∑Ô∏è **Clasificaci√≥n de Revisiones de Productos en un Ecommerce con Transformers** üõíüìä\n",
        "\n",
        "El notebook est√° enfocado en procesamiento de texto con Transformers para clasificaci√≥n de sentimientos en rese√±as de ecommerce en portugu√©s. Los pr√≥ximos pasos despu√©s de descargar y descomprimir los datasets son:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìñ **√çndice** üìë\n",
        "1Ô∏è‚É£ [Introducci√≥n](#introduccion)<br>\n",
        "2Ô∏è‚É£ [Problema del Negocio](#problema)<br>\n",
        "3Ô∏è‚É£ [An√°lisis de Datos](#analisis)<br>\n",
        "4Ô∏è‚É£ [Preprocesamiento de Datos](#preprocesamiento)<br>\n",
        "5Ô∏è‚É£ [Entrenamiento del Modelo](#entrenamiento)<br>\n",
        "6Ô∏è‚É£ [Evaluaci√≥n y Predicci√≥n](#evaluacion)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù **1. Introducci√≥n**  <a id='introduccion'></a>\n",
        "\n",
        "En este proyecto, utilizamos un modelo **Transformer** para clasificar revisiones de productos en un ecommerce. Nuestro objetivo es detectar autom√°ticamente si una rese√±a es **positiva** üòä o **negativa** üòû bas√°ndonos en el texto ingresado por los usuarios.\n",
        "\n",
        "‚ö†Ô∏è **Nota**: Este proyecto **NO** se enfoca en un an√°lisis exploratorio detallado de los datos, sino en el desarrollo y ajuste fino del modelo de clasificaci√≥n.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## ‚ùì **2. Problema del Negocio**  <a id='problema'></a>\n",
        "\n",
        "üí° **Objetivo**: Clasificar autom√°ticamente las revisiones de productos en el ecommerce **Olist** seg√∫n el sentimiento expresado en el texto.\n",
        "\n",
        "üîç **Beneficio**: Permite a la empresa entender mejor la satisfacci√≥n de los clientes y tomar acciones basadas en los comentarios recibidos.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaAg1-FcX4-F"
      },
      "source": [
        "## üñ•Ô∏è **3. Configuraci√≥n del Entorno**  <a id='configuracion'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para ejecutar este proyecto, es necesario instalar las siguientes librer√≠as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iuxJDXIFX5Wy",
        "outputId": "141d80b4-3216-4390-9b05-9d82526aee9a"
      },
      "outputs": [],
      "source": [
        "# Instalaci√≥n bibliotecas necesarias\n",
        "\n",
        "# Transformers para trabajar con modelos de NLP\n",
        "%pip install transformers datasets\n",
        "\n",
        "# Acceso a datasets desde Kaggle\n",
        "%pip install kaggle\n",
        "\n",
        "# Aceleraci√≥n del entrenamiento en GPU/TPU\n",
        "%pip install accelerate -U\n",
        "\n",
        "# Librer√≠as principales para modelos de deep learning\n",
        "%pip install torch\n",
        "%pip install transformers[torch]\n",
        "\n",
        "# Interfaz gr√°fica para pruebas de modelo\n",
        "%pip install gradio\n",
        "\n",
        "# Instalaci√≥n de bibliotecas esenciales para an√°lisis de datos y aprendizaje autom√°tico\n",
        "%pip install  install pandas t\n",
        "%pip install tensorflow \n",
        "%pip install scikit-learn\n",
        "\n",
        "# Mejorar la experiencia en Jupyter Notebook\n",
        "%pip install --upgrade jupyter ipywidgets\n",
        "\n",
        "# Instalar tf-keras para compatibilidad con TensorFlow\n",
        "%pip install tf-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ **Desactivar los warnings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "import tensorflow as tf\n",
        "from transformers.utils import logging\n",
        "\n",
        "# Desactivar warnings de TensorFlow\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# Desactivar warnings de Transformers\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# Desactivar warnings generales de Python\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ **Configuraci√≥n de la API de Kaggle** (si los datos provienen de Kaggle)\n",
        "\n",
        "Seleccionar el archivo kaggle.json y moverlo a la carpeta .kaggle de tu usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ kaggle.json movido a: C:\\Users\\esaa2\\.kaggle\\kaggle.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# üìå Pedir manualmente la ruta de kaggle.json\n",
        "file_path = input(\"üîç Ingresa la ruta completa de tu archivo kaggle.json: \")\n",
        "\n",
        "# üìå Validar si la ruta ingresada es correcta\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"‚ö†Ô∏è ERROR: La ruta ingresada no es v√°lida. Verifica el archivo y vuelve a intentarlo.\")\n",
        "else:\n",
        "    # üìå Ruta destino en .kaggle\n",
        "    kaggle_dir = os.path.join(os.path.expanduser(\"~\"), \".kaggle\")\n",
        "    os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "    destino = os.path.join(kaggle_dir, \"kaggle.json\")\n",
        "    shutil.move(file_path, destino)\n",
        "    print(f\"‚úÖ kaggle.json movido a: {destino}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O simplemente Crea la carpeta .kaggle en \"tu usuario\" de Windows y copia manualmente kaggle.json a la carpeta .kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Descargar el dataset desde Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\n",
            "Dataset descargado y extra√≠do en: datasets\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Configurar Kaggle API\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Descargar dataset\n",
        "dataset_name = \"olistbr/brazilian-ecommerce\"\n",
        "save_path = \"datasets\"\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "api.dataset_download_files(dataset_name, path=save_path, unzip=True)\n",
        "print(\"Dataset descargado y extra√≠do en:\", save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Verificar que todo funciona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ kaggle.json est√° en: C:\\Users\\esaa2\\.kaggle\\kaggle.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "kaggle_dir = os.path.join(os.path.expanduser(\"~\"), \".kaggle\")\n",
        "json_path = os.path.join(kaggle_dir, \"kaggle.json\")\n",
        "\n",
        "if os.path.exists(json_path):\n",
        "    print(f\"‚úÖ kaggle.json est√° en: {json_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è ERROR: No se encontr√≥ kaggle.json en la ubicaci√≥n esperada.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä **4. An√°lisis de Datos**  <a id='analisis'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ **Carga de Datos**: Importamos el dataset con rese√±as de productos \"olist_order_reviews_dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset cargado correctamente.\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "review_id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "order_id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "review_score",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "review_comment_title",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "review_comment_message",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "review_creation_date",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "review_answer_timestamp",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "1f620dbe-df9d-4aa1-9f69-cf0210c21294",
              "rows": [
                [
                  "0",
                  "7bc2406110b926393aa56f80a40eba40",
                  "73fc7af87114b39712e6da79b0a377eb",
                  "4",
                  null,
                  null,
                  "2018-01-18 00:00:00",
                  "2018-01-18 21:46:59"
                ],
                [
                  "1",
                  "80e641a11e56f04c1ad469d5645fdfde",
                  "a548910a1c6147796b98fdf73dbeba33",
                  "5",
                  null,
                  null,
                  "2018-03-10 00:00:00",
                  "2018-03-11 03:05:13"
                ],
                [
                  "2",
                  "228ce5500dc1d8e020d8d1322874b6f0",
                  "f9e4b658b201a9f2ecdecbb34bed034b",
                  "5",
                  null,
                  null,
                  "2018-02-17 00:00:00",
                  "2018-02-18 14:36:24"
                ],
                [
                  "3",
                  "e64fb393e7b32834bb789ff8bb30750e",
                  "658677c97b385a9be170737859d3511b",
                  "5",
                  null,
                  "Recebi bem antes do prazo estipulado.",
                  "2017-04-21 00:00:00",
                  "2017-04-21 22:02:06"
                ],
                [
                  "4",
                  "f7c4243c7fe1938f181bec41a392bdeb",
                  "8e6bfb81e283fa7e4f11123a3fb894f1",
                  "5",
                  null,
                  "Parab√©ns lojas lannister adorei comprar pela Internet seguro e pr√°tico Parab√©ns a todos feliz P√°scoa",
                  "2018-03-01 00:00:00",
                  "2018-03-02 10:26:53"
                ]
              ],
              "shape": {
                "columns": 7,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>order_id</th>\n",
              "      <th>review_score</th>\n",
              "      <th>review_comment_title</th>\n",
              "      <th>review_comment_message</th>\n",
              "      <th>review_creation_date</th>\n",
              "      <th>review_answer_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7bc2406110b926393aa56f80a40eba40</td>\n",
              "      <td>73fc7af87114b39712e6da79b0a377eb</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-01-18 00:00:00</td>\n",
              "      <td>2018-01-18 21:46:59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80e641a11e56f04c1ad469d5645fdfde</td>\n",
              "      <td>a548910a1c6147796b98fdf73dbeba33</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-03-10 00:00:00</td>\n",
              "      <td>2018-03-11 03:05:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>228ce5500dc1d8e020d8d1322874b6f0</td>\n",
              "      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-02-17 00:00:00</td>\n",
              "      <td>2018-02-18 14:36:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>e64fb393e7b32834bb789ff8bb30750e</td>\n",
              "      <td>658677c97b385a9be170737859d3511b</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Recebi bem antes do prazo estipulado.</td>\n",
              "      <td>2017-04-21 00:00:00</td>\n",
              "      <td>2017-04-21 22:02:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f7c4243c7fe1938f181bec41a392bdeb</td>\n",
              "      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Parab√©ns lojas lannister adorei comprar pela I...</td>\n",
              "      <td>2018-03-01 00:00:00</td>\n",
              "      <td>2018-03-02 10:26:53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          review_id                          order_id  \\\n",
              "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
              "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
              "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
              "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
              "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
              "\n",
              "   review_score review_comment_title  \\\n",
              "0             4                  NaN   \n",
              "1             5                  NaN   \n",
              "2             5                  NaN   \n",
              "3             5                  NaN   \n",
              "4             5                  NaN   \n",
              "\n",
              "                              review_comment_message review_creation_date  \\\n",
              "0                                                NaN  2018-01-18 00:00:00   \n",
              "1                                                NaN  2018-03-10 00:00:00   \n",
              "2                                                NaN  2018-02-17 00:00:00   \n",
              "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
              "4  Parab√©ns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
              "\n",
              "  review_answer_timestamp  \n",
              "0     2018-01-18 21:46:59  \n",
              "1     2018-03-11 03:05:13  \n",
              "2     2018-02-18 14:36:24  \n",
              "3     2017-04-21 22:02:06  \n",
              "4     2018-03-02 10:26:53  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Definir la ruta correcta del dataset descargado\n",
        "dataset_path = \"datasets/olist_order_reviews_dataset.csv\"\n",
        "\n",
        "# Verificar si el archivo existe\n",
        "if os.path.exists(dataset_path):\n",
        "    df = pd.read_csv(dataset_path)\n",
        "    print(\"‚úÖ Dataset cargado correctamente.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è ERROR: No se encontr√≥ el archivo. Verifica la ruta.\")\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Verificamos la calidad de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99224 entries, 0 to 99223\n",
            "Data columns (total 7 columns):\n",
            " #   Column                   Non-Null Count  Dtype \n",
            "---  ------                   --------------  ----- \n",
            " 0   review_id                99224 non-null  object\n",
            " 1   order_id                 99224 non-null  object\n",
            " 2   review_score             99224 non-null  int64 \n",
            " 3   review_comment_title     11568 non-null  object\n",
            " 4   review_comment_message   40977 non-null  object\n",
            " 5   review_creation_date     99224 non-null  object\n",
            " 6   review_answer_timestamp  99224 non-null  object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 5.3+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è **5. Preprocesamiento de Datos**  <a id='preprocesamiento'></a>\n",
        "\n",
        "‚ö†Ô∏è **Nota**: No realizamos un an√°lisis profundo de datos, sino una **limpieza justa y necesaria** para preparar los datos para el modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Filtrar datos y crear la columna de sentimiento<br>\n",
        "üîπ **Limpieza**: Eliminamos filas con valores nulos.<br> \n",
        "üîπ **Creaci√≥n de Etiquetas**: Convertimos las calificaciones en **positivas (1)** o **negativas (0)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "review_comment_message",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "review_score",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "sentiment",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "802ec539-b882-47dd-97af-ad54820b1a55",
              "rows": [
                [
                  "3",
                  "Recebi bem antes do prazo estipulado.",
                  "5",
                  "1"
                ],
                [
                  "4",
                  "Parab√©ns lojas lannister adorei comprar pela Internet seguro e pr√°tico Parab√©ns a todos feliz P√°scoa",
                  "5",
                  "1"
                ],
                [
                  "9",
                  "aparelho eficiente. no site a marca do aparelho esta impresso como 3desinfector e ao chegar esta com outro nome...atualizar com a marca correta uma vez que √© o mesmo aparelho",
                  "4",
                  "1"
                ],
                [
                  "12",
                  "Mas um pouco ,travando...pelo valor ta Boa.\r\n",
                  "4",
                  "1"
                ],
                [
                  "15",
                  "Vendedor confi√°vel, produto ok e entrega antes do prazo.",
                  "5",
                  "1"
                ]
              ],
              "shape": {
                "columns": 3,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_comment_message</th>\n",
              "      <th>review_score</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Recebi bem antes do prazo estipulado.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Parab√©ns lojas lannister adorei comprar pela I...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Vendedor confi√°vel, produto ok e entrega antes...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               review_comment_message  review_score  sentiment\n",
              "3               Recebi bem antes do prazo estipulado.             5          1\n",
              "4   Parab√©ns lojas lannister adorei comprar pela I...             5          1\n",
              "9   aparelho eficiente. no site a marca do aparelh...             4          1\n",
              "12    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n             4          1\n",
              "15  Vendedor confi√°vel, produto ok e entrega antes...             5          1"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Eliminar filas con comentarios vac√≠os y Selecciona solamente las l√≠neas con comentarios y puntuaciones\n",
        "df = df.dropna(subset=['review_comment_message', 'review_score'])\n",
        "\n",
        "# Crear columna de sentimientos (1 = Positivo, 0 = Negativo)\n",
        "df['sentiment'] = df['review_score'].apply(lambda score: 1 if score >= 4 else 0)\n",
        "\n",
        "df[['review_comment_message', 'review_score', 'sentiment']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ **6. Entrenamiento del Modelo**  <a id='entrenamiento'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ **Divisi√≥n de Datos**: Separaci√≥n en conjuntos de entrenamiento y prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos de entrenamiento: 3688\n",
            "Datos de prueba: 410\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Reducir el tama√±o de los datos para acelerar el entrenamiento\n",
        "df_sample = df.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento (90%) y prueba (10%)\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df_sample['review_comment_message'], df_sample['sentiment'], test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Datos de entrenamiento: {len(train_texts)}\")\n",
        "print(f\"Datos de prueba: {len(test_texts)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ **Tokenizaci√≥n**: Preparaci√≥n del texto para el modelo Transformer (Tokenizaci√≥n con AutoTokenizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Tokenizaci√≥n completada.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Usar un tokenizer preentrenado en portugu√©s\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "# Tokenizar los textos de entrenamiento y prueba\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "print(\"‚úÖ Tokenizaci√≥n completada.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Creaci√≥n y compilaci√≥n del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Modelo compilado correctamente.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "# Cargar el modelo de transformers con 2 clases (positivo/negativo)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"neuralmind/bert-base-portuguese-cased\", num_labels=2\n",
        ")\n",
        "\n",
        "# Configurar optimizador y funci√≥n de p√©rdida\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
        "print(\"‚úÖ Modelo compilado correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Convertir datos en `tf.data.Dataset` para entrenamiento\n",
        "\n",
        "Crear datasets en formato TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Datos convertidos a `tf.data.Dataset`.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices((\n",
        "        dict(train_encodings), train_labels\n",
        "    ))\n",
        "    .shuffle(1000)\n",
        "    .batch(32)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_dataset = (\n",
        "    tf.data.Dataset.from_tensor_slices((\n",
        "        dict(test_encodings), test_labels\n",
        "    ))\n",
        "    .batch(32)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Datos convertidos a `tf.data.Dataset`.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "116/116 [==============================] - 1482s 12s/step - loss: 0.3269 - accuracy: 0.8682 - val_loss: 0.2730 - val_accuracy: 0.9073\n",
            "‚úÖ Entrenamiento completado.\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    epochs=1 # 3 (Reducir la cantidad de epochs )\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Entrenamiento completado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Guardado del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Modelo guardado en: sentiment_analysis_model\n"
          ]
        }
      ],
      "source": [
        "model_dir = \"sentiment_analysis_model\"\n",
        "\n",
        "# Guardar el modelo y el tokenizer\n",
        "model.save_pretrained(model_dir)\n",
        "tokenizer.save_pretrained(model_dir)\n",
        "\n",
        "print(f\"‚úÖ Modelo guardado en: {model_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Cargar el modelo guardado para predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Modelo cargado y recompilado correctamente.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "\n",
        "# Cargar modelo y tokenizer\n",
        "model_dir = \"sentiment_analysis_model\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "model = TFBertForSequenceClassification.from_pretrained(model_dir)\n",
        "\n",
        "# Recompilar el modelo\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"‚úÖ Modelo cargado y recompilado correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ **7. Evaluaci√≥n y Predicci√≥n**  <a id='evaluacion'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Evaluaci√≥n del modelo en los datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 39s 2s/step - loss: 0.2730 - accuracy: 0.9073\n",
            "üìä Precisi√≥n del modelo en test: 0.9073\n"
          ]
        }
      ],
      "source": [
        "# Evaluar en datos de prueba\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"üìä Precisi√≥n del modelo en test: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Predicci√≥n con nuevos comentarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîé Predicci√≥n 1: Positivo üòä\n",
            "üîé Predicci√≥n 2: Negativo üòû\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    # Tokenizar el texto\n",
        "    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True, max_length=128)\n",
        "    \n",
        "    # Hacer predicci√≥n\n",
        "    logits = model(**inputs).logits\n",
        "    predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n",
        "\n",
        "    # Convertir la predicci√≥n en etiqueta\n",
        "    sentiment_label = \"Positivo üòä\" if predicted_class == 1 else \"Negativo üòû\"\n",
        "    return sentiment_label\n",
        "\n",
        "# Prueba con ejemplos\n",
        "ejemplo1 = \"O produto √© maravilhoso, chegou r√°pido e tem √≥tima qualidade!\"\n",
        "ejemplo2 = \"N√£o gostei, o produto veio com defeito e o atendimento foi p√©ssimo.\"\n",
        "\n",
        "print(f\"üîé Predicci√≥n 1: {predict_sentiment(ejemplo1)}\")\n",
        "print(f\"üîé Predicci√≥n 2: {predict_sentiment(ejemplo2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ **8. Evaluaci√≥n y Predicci√≥n con GRADIO**  <a id='gradio'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# üí° Importamos Gradio para crear la interfaz gr√°fica interactiva\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "\n",
        "# üìå Definimos la funci√≥n que Gradio usar√° para hacer predicciones\n",
        "def classify_review(text):\n",
        "    \"\"\"\n",
        "    Funci√≥n que clasifica una rese√±a de cliente como 'Positiva' o 'Negativa'\n",
        "    utilizando el modelo BERT entrenado.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True)\n",
        "    outputs = model(inputs)[0]\n",
        "    prediction = tf.nn.softmax(outputs, axis=1)\n",
        "    label = \"Positiva\" if tf.argmax(prediction, axis=1).numpy()[0] == 1 else \"Negativa\"\n",
        "    return label\n",
        "\n",
        "# üéõÔ∏è Creamos la interfaz de usuario con Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=classify_review,  # Funci√≥n de clasificaci√≥n\n",
        "    inputs=\"text\",  # Entrada: Texto del usuario\n",
        "    outputs=\"label\",  # Salida: Predicci√≥n de sentimiento\n",
        "    title=\"üîç Clasificaci√≥n de Rese√±as con BERT\",\n",
        "    description=\"Ingrese una rese√±a y el modelo la clasificar√° como Positiva o Negativa.\",\n",
        "    theme=\"default\"\n",
        ")\n",
        "\n",
        "# üöÄ Lanzamos la interfaz\n",
        "iface.launch()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÜ **Conclusi√≥n**\n",
        "\n",
        "‚úîÔ∏è Se ha entrenado un modelo Transformer para clasificar rese√±as de productos.<br>\n",
        "‚úîÔ∏è El modelo predice si una rese√±a es positiva o negativa con precisi√≥n.<br>\n",
        "‚úîÔ∏è Puede ser implementado en un ecommerce para an√°lisis automatizado de satisfacci√≥n del cliente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**üöÄ Pr√≥ximos Pasos:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üîπ Mejorar el modelo con m√°s datos y entrenamiento prolongado.<br>\n",
        "üîπ Aplicar t√©cnicas de reducci√≥n de ruido en los textos.<br>\n",
        "üîπ Evaluar el modelo con m√©tricas adicionales como `F1-score` y `AUC-ROC`.<br>\n",
        "üîπ **Para un ajuste fino m√°s robusto:**<br>\n",
        "   1Ô∏è‚É£ Aumentar el n√∫mero de epochs (ejemplo: `epochs=3 o 5`).<br>\n",
        "   2Ô∏è‚É£ Usar congelaci√≥n de capas para entrenar solo algunas partes del modelo BERT.<br>\n",
        "   3Ô∏è‚É£ Aplicar estrategias de regularizaci√≥n como `dropout` para evitar sobreajuste.<br><br>\n",
        "\n",
        "üîé **Conclusi√≥n**: El ajuste fino es el proceso de entrenar un modelo preentrenado en un nuevo conjunto de datos con una tarea espec√≠fica. En este caso, hemos afinado BERT para clasificar rese√±as en Olist. üöÄ\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üì¢ **Gracias por revisar este proyecto!** üôå"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
